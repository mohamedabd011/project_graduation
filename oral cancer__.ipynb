{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Images [ From Folders ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        img=cv2.resize(img,(224,224))             # Set whatever size you want \n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "1030\n",
      "(224, 224, 3)\n",
      "2489\n",
      "(224, 224, 3)\n",
      "231\n",
      "(224, 224, 3)\n",
      "1122\n",
      "(224, 224, 3)\n",
      "525\n"
     ]
    }
   ],
   "source": [
    "class1=load_images_from_folder('D:\\\\final project\\\\normal')\n",
    "print(class1[0].shape)\n",
    "print(len(class1))\n",
    "\n",
    "class2=load_images_from_folder('D:\\\\final project\\\\ulcer')\n",
    "print(class2[0].shape)\n",
    "print(len(class2))\n",
    "\n",
    "class3=load_images_from_folder('D:\\\\final project\\\\high_risk GVHD')\n",
    "print(class3[0].shape)\n",
    "print(len(class3))\n",
    "\n",
    "class4=load_images_from_folder('D:\\\\final project\\\\high__risk HPV')\n",
    "print(class4[0].shape)\n",
    "print(len(class4))\n",
    "\n",
    "class5=load_images_from_folder('D:\\\\final project\\\\cancer')\n",
    "print(class5[0].shape)\n",
    "print(len(class5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train=[]\n",
    "Data=[class1,class2,class3,class4,class5]\n",
    "for c in Data :\n",
    "    for i,image in enumerate(c) :\n",
    "        image=image/255  #norm\n",
    "        X_train.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={\n",
    "    '0':'normal',\n",
    "    '1': 'ulcer',\n",
    "    '2': 'high_risk GVHD',\n",
    "    '3': 'high_risk H',\n",
    "    '4':'cancer',\n",
    "}\n",
    "y_train=[0]*len(class1)+[1]*len(class2)+[2]*len(class3)+[3]*len(class4)+[4]*len(class5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images Count : 5397 Training Labels Count: 5397\n"
     ]
    }
   ],
   "source": [
    "print('Training Images Count :' ,len(X_train),'Training Labels Count:',len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparing Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "22\n",
      "(224, 224, 3)\n",
      "20\n",
      "(224, 224, 3)\n",
      "13\n",
      "(224, 224, 3)\n",
      "26\n",
      "(224, 224, 3)\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "class1test=load_images_from_folder('D:\\\\final project\\\\normal test')\n",
    "print(class1test[0].shape)\n",
    "print(len(class1test))\n",
    "\n",
    "class2test=load_images_from_folder('D:\\\\final project\\\\ulcer test')\n",
    "print(class2test[0].shape)\n",
    "print(len(class2test))\n",
    "\n",
    "class3test=load_images_from_folder('D:\\\\final project\\\\high_risk GVHD test')\n",
    "print(class3test[0].shape)\n",
    "print(len(class3test))\n",
    "\n",
    "class4test=load_images_from_folder('D:\\\\final project\\\\high__risk HPV test')\n",
    "print(class4test[0].shape)\n",
    "print(len(class4test))\n",
    "\n",
    "class5test=load_images_from_folder('D:\\\\final project\\\\cancer test')\n",
    "print(class5test[0].shape)\n",
    "print(len(class5test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_test=[]\n",
    "Data=[class1test,class2test,class3test,class4test,class5test]\n",
    "for c in Data :\n",
    "    for i,image in enumerate(c) :\n",
    "        image=image/255  # Norm   0-1\n",
    "        X_test.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelstest={\n",
    "    '0':'normal',\n",
    "    '1': 'ulcer',\n",
    "    '2': 'high_risk GVHD',\n",
    "    '3': 'high_risk H',\n",
    "    '4':'cancer',\n",
    "}\n",
    "y_test=[0]*len(class1test)+[1]*len(class2test)+[2]*len(class3test)+[3]*len(class4test)+[4]*len(class5test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Images Count : 92 Testing Labels Count: 92\n"
     ]
    }
   ],
   "source": [
    "print('Testing Images Count :' ,len(X_test),'Testing Labels Count:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building The Model\n",
    "##### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_=np.asarray(X_train)\n",
    "X_test_=np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5397, 224, 224, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = np.asarray(y_train)\n",
    "y_test_=np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transfer learning from skin cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# arch_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "#model.save(\"network.h5\")\n",
    "model_A = load_model(\"full_skin_cancer_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"full_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Image_RGB_In (InputLayer)   [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " gaussian_noise_1 (GaussianN  (None, 224, 224, 3)      0         \n",
      " oise)                                                           \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 1280)       5120      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               16056576  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,321,479\n",
      "Trainable params: 18,284,807\n",
      "Non-trainable params: 36,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_A.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note :-\n",
    "--------------------------------\n",
    "   \n",
    "   input_size = 224*224\n",
    "---------------------------------\n",
    "   num_classes=7\n",
    "---------------------------------   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(5, activation=\"softmax\")) ## for example ==> 5 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gaussian_noise_1 (GaussianN  (None, 224, 224, 3)      0         \n",
      " oise)                                                           \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 1280)       5120      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               16056576  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,319,680\n",
      "Trainable params: 18,283,008\n",
      "Non-trainable params: 36,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.models.Sequential(model_A.layers[:-1]).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gaussian_noise_1 (GaussianN  (None, 224, 224, 3)      0         \n",
      " oise)                                                           \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 1280)       5120      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               16056576  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,320,965\n",
      "Trainable params: 18,284,293\n",
      "Non-trainable params: 36,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B_on_A.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NourTech\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# freezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-3]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update lr === high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NourTech\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 154s 878ms/step - loss: 1.5576 - accuracy: 0.5027 - val_loss: 1.2180 - val_accuracy: 0.4565\n",
      "Epoch 2/15\n",
      "169/169 [==============================] - 140s 827ms/step - loss: 1.0254 - accuracy: 0.5968 - val_loss: 1.1923 - val_accuracy: 0.5652\n",
      "Epoch 3/15\n",
      "169/169 [==============================] - 130s 767ms/step - loss: 0.8835 - accuracy: 0.6496 - val_loss: 1.2633 - val_accuracy: 0.5326\n",
      "Epoch 4/15\n",
      "169/169 [==============================] - 126s 747ms/step - loss: 0.7876 - accuracy: 0.6769 - val_loss: 0.9502 - val_accuracy: 0.6739\n",
      "Epoch 5/15\n",
      "169/169 [==============================] - 119s 706ms/step - loss: 0.7086 - accuracy: 0.7076 - val_loss: 1.0133 - val_accuracy: 0.6304\n",
      "Epoch 6/15\n",
      "169/169 [==============================] - 122s 720ms/step - loss: 0.6719 - accuracy: 0.7239 - val_loss: 1.0067 - val_accuracy: 0.6739\n",
      "Epoch 7/15\n",
      "169/169 [==============================] - 126s 747ms/step - loss: 0.6238 - accuracy: 0.7410 - val_loss: 0.9805 - val_accuracy: 0.6957\n",
      "Epoch 8/15\n",
      "169/169 [==============================] - 162s 959ms/step - loss: 0.5733 - accuracy: 0.7628 - val_loss: 1.0509 - val_accuracy: 0.7065\n",
      "Epoch 9/15\n",
      "169/169 [==============================] - 123s 728ms/step - loss: 0.5702 - accuracy: 0.7636 - val_loss: 1.0423 - val_accuracy: 0.6522\n",
      "Epoch 10/15\n",
      "169/169 [==============================] - 122s 721ms/step - loss: 0.5569 - accuracy: 0.7784 - val_loss: 1.0532 - val_accuracy: 0.6522\n",
      "Epoch 11/15\n",
      "169/169 [==============================] - 115s 683ms/step - loss: 0.5284 - accuracy: 0.7812 - val_loss: 0.8394 - val_accuracy: 0.7283\n",
      "Epoch 12/15\n",
      "169/169 [==============================] - 114s 674ms/step - loss: 0.4991 - accuracy: 0.7869 - val_loss: 1.1700 - val_accuracy: 0.7283\n",
      "Epoch 13/15\n",
      "169/169 [==============================] - 114s 672ms/step - loss: 0.4731 - accuracy: 0.8084 - val_loss: 0.9170 - val_accuracy: 0.7500\n",
      "Epoch 14/15\n",
      "169/169 [==============================] - 113s 667ms/step - loss: 0.4611 - accuracy: 0.8043 - val_loss: 1.0871 - val_accuracy: 0.6739\n",
      "Epoch 15/15\n",
      "169/169 [==============================] - 109s 643ms/step - loss: 0.4354 - accuracy: 0.8168 - val_loss: 0.8339 - val_accuracy: 0.7065\n"
     ]
    }
   ],
   "source": [
    "model_B_on_A.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model_B_on_A.fit(X_train_, y_train_, epochs=15, validation_data=(X_test_, y_test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# unfreezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-3]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "optim=tf.keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr == low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "169/169 [==============================] - 499s 3s/step - loss: 1.3571 - accuracy: 0.5618 - val_loss: 3.9083 - val_accuracy: 0.3696\n",
      "Epoch 2/30\n",
      "169/169 [==============================] - 475s 3s/step - loss: 0.9470 - accuracy: 0.6429 - val_loss: 3.0007 - val_accuracy: 0.4457\n",
      "Epoch 3/30\n",
      "169/169 [==============================] - 486s 3s/step - loss: 0.7913 - accuracy: 0.7078 - val_loss: 2.6770 - val_accuracy: 0.4457\n",
      "Epoch 4/30\n",
      "169/169 [==============================] - 485s 3s/step - loss: 0.6485 - accuracy: 0.7554 - val_loss: 2.8744 - val_accuracy: 0.4239\n",
      "Epoch 5/30\n",
      "169/169 [==============================] - 485s 3s/step - loss: 0.5244 - accuracy: 0.8079 - val_loss: 7.2656 - val_accuracy: 0.3261\n",
      "Epoch 6/30\n",
      "169/169 [==============================] - 482s 3s/step - loss: 0.4714 - accuracy: 0.8314 - val_loss: 12.0061 - val_accuracy: 0.3152\n",
      "Epoch 7/30\n",
      "169/169 [==============================] - 486s 3s/step - loss: 0.4034 - accuracy: 0.8590 - val_loss: 14.6387 - val_accuracy: 0.3587\n",
      "Epoch 8/30\n",
      "169/169 [==============================] - 491s 3s/step - loss: 0.3323 - accuracy: 0.8805 - val_loss: 3.7814 - val_accuracy: 0.4348\n",
      "Epoch 9/30\n",
      "169/169 [==============================] - 482s 3s/step - loss: 0.2829 - accuracy: 0.8996 - val_loss: 7.4892 - val_accuracy: 0.4022\n",
      "Epoch 10/30\n",
      "169/169 [==============================] - 487s 3s/step - loss: 0.2355 - accuracy: 0.9207 - val_loss: 5.2685 - val_accuracy: 0.3696\n",
      "Epoch 11/30\n",
      "169/169 [==============================] - 484s 3s/step - loss: 0.1946 - accuracy: 0.9383 - val_loss: 8.8722 - val_accuracy: 0.4457\n",
      "Epoch 12/30\n",
      "169/169 [==============================] - 488s 3s/step - loss: 0.2065 - accuracy: 0.9364 - val_loss: 7.8898 - val_accuracy: 0.4348\n",
      "Epoch 13/30\n",
      "169/169 [==============================] - 486s 3s/step - loss: 0.1780 - accuracy: 0.9435 - val_loss: 4.2936 - val_accuracy: 0.4022\n",
      "Epoch 14/30\n",
      "169/169 [==============================] - 484s 3s/step - loss: 0.1569 - accuracy: 0.9492 - val_loss: 3.1996 - val_accuracy: 0.4565\n",
      "Epoch 15/30\n",
      "169/169 [==============================] - 484s 3s/step - loss: 0.1155 - accuracy: 0.9631 - val_loss: 2.6016 - val_accuracy: 0.4891\n",
      "Epoch 16/30\n",
      "169/169 [==============================] - 484s 3s/step - loss: 0.0955 - accuracy: 0.9720 - val_loss: 6.3435 - val_accuracy: 0.4130\n",
      "Epoch 17/30\n",
      "169/169 [==============================] - 479s 3s/step - loss: 0.1086 - accuracy: 0.9691 - val_loss: 4.0330 - val_accuracy: 0.4565\n",
      "Epoch 18/30\n",
      "169/169 [==============================] - 492s 3s/step - loss: 0.0981 - accuracy: 0.9724 - val_loss: 7.4780 - val_accuracy: 0.4457\n",
      "Epoch 19/30\n",
      "169/169 [==============================] - 490s 3s/step - loss: 0.0836 - accuracy: 0.9768 - val_loss: 10.8180 - val_accuracy: 0.4022\n",
      "Epoch 20/30\n",
      "169/169 [==============================] - 482s 3s/step - loss: 0.1237 - accuracy: 0.9683 - val_loss: 4.6766 - val_accuracy: 0.4239\n",
      "Epoch 21/30\n",
      "169/169 [==============================] - 487s 3s/step - loss: 0.1018 - accuracy: 0.9698 - val_loss: 6.5755 - val_accuracy: 0.3587\n",
      "Epoch 22/30\n",
      "169/169 [==============================] - 484s 3s/step - loss: 0.0865 - accuracy: 0.9772 - val_loss: 4.4532 - val_accuracy: 0.4783\n",
      "Epoch 23/30\n",
      "169/169 [==============================] - 480s 3s/step - loss: 0.0683 - accuracy: 0.9813 - val_loss: 3.8446 - val_accuracy: 0.4348\n",
      "Epoch 24/30\n",
      "169/169 [==============================] - 487s 3s/step - loss: 0.0720 - accuracy: 0.9794 - val_loss: 8.9165 - val_accuracy: 0.4022\n",
      "Epoch 25/30\n",
      "169/169 [==============================] - 481s 3s/step - loss: 0.0812 - accuracy: 0.9804 - val_loss: 8.3263 - val_accuracy: 0.3478\n",
      "Epoch 26/30\n",
      "169/169 [==============================] - 483s 3s/step - loss: 0.0836 - accuracy: 0.9772 - val_loss: 3.5028 - val_accuracy: 0.4891\n",
      "Epoch 27/30\n",
      "169/169 [==============================] - 488s 3s/step - loss: 0.0669 - accuracy: 0.9807 - val_loss: 4.6912 - val_accuracy: 0.4130\n",
      "Epoch 28/30\n",
      "169/169 [==============================] - 486s 3s/step - loss: 0.0734 - accuracy: 0.9811 - val_loss: 6.6630 - val_accuracy: 0.3913\n",
      "Epoch 29/30\n",
      "169/169 [==============================] - 484s 3s/step - loss: 0.0914 - accuracy: 0.9744 - val_loss: 4.8486 - val_accuracy: 0.4130\n",
      "Epoch 30/30\n",
      "169/169 [==============================] - 486s 3s/step - loss: 0.0521 - accuracy: 0.9854 - val_loss: 4.9512 - val_accuracy: 0.3696\n"
     ]
    }
   ],
   "source": [
    "model_B_on_A.compile(optimizer=optim,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model_B_on_A.fit(X_train_, y_train_, epochs=30, validation_data=(X_test_, y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.save_weights(\"oral_cancer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.models.Sequential(model_A.layers[:-1])\n",
    "model.add(keras.layers.Dense(5, activation=\"softmax\")) ## for example ==> 5 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('oral_cancer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = model.input_shape[1:3]\n",
    "image_uri = 'high risk.JFIF'\n",
    "im = keras.preprocessing.image.load_img(image_uri, target_size=dims)\n",
    "doc = keras.preprocessing.image.img_to_array(im)\n",
    "doc = np.expand_dims(doc, axis=0)\n",
    "prediction = model.predict(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.0764488e-10, 1.7848551e-04, 9.9982005e-01, 1.4530974e-06,\n",
       "        2.6455322e-09]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
